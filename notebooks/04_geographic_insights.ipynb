{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Q4: Geographic Distribution & Regional Specialization\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "1. **Distribution:** Where are clinical trials registered, and how concentrated is the market?\n",
    "2. **Specialization:** Do countries show relative over-/under-representation in therapeutic areas?\n",
    "3. **Trends:** Has the geographic distribution shifted over time?\n",
    "\n",
    "## Structure\n",
    "\n",
    "| Section | Question | Approach |\n",
    "|---------|----------|----------|\n",
    "| 2. Distribution | Market concentration | HHI with bootstrap CI |\n",
    "| 3. Specialization | Regional patterns | Location Quotient (descriptive, no CI) |\n",
    "| 4. Temporal | Distribution shifts | JSD, share changes |\n",
    "| Appendix A | Site counts | Descriptive |\n",
    "\n",
    "## Critical Caveats\n",
    "\n",
    "**This analysis is exploratory/descriptive, not inferential.**\n",
    "\n",
    "1. **Condition labels are not normalized.** The registry uses free-text condition names; \"breast cancer\", \"breast neoplasm\", and \"carcinoma of breast\" appear as separate conditions. Without deduplication, LQ values measure registration patterns in fragmented labels, not true specialization.\n",
    "\n",
    "2. **Multi-condition trials inflate LQ denominators.** A trial with 3 conditions contributes 3× to condition totals. High LQ for conditions that frequently co-occur may be artifacts.\n",
    "\n",
    "3. **Multinational trials assigned to single country.** ~20–35% of trials have sites in multiple countries but are assigned to one \"primary\" country (mode of sites). This inflates concentration for top markets.\n",
    "\n",
    "4. **Trial counts ≠ enrollment capacity.** A high LQ for India in oncology means India registers many oncology trials relative to its portfolio—not that India has proportional enrollment capacity. Site selection requires enrollment rate data.\n",
    "\n",
    "5. **Temporal analysis reflects registry coverage, not only trial activity.** FDAAA 2007 mandated US registration; pre-2007 data is US-biased. Non-US registries (EUCTR, ChiCTR) grew over time.\n",
    "\n",
    "## Scope\n",
    "\n",
    "- **Data:** ClinicalTrials.gov, start year 1990–2025\n",
    "- **Primary country:** Mode of site locations; ties broken arbitrarily (first in SQL sort)\n",
    "- **LQ interpretation:** Over-representation relative to global average, not validated expertise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Setup\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu, spearmanr\n",
    "from IPython.display import display, Markdown\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Project root for imports\n",
    "PROJECT_ROOT = Path('..')\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Shared utilities\n",
    "from src.data.loader import load_sql_query, get_db_connection\n",
    "from src.analysis.viz import DEFAULT_COLORS, create_horizontal_bar_chart\n",
    "from src.analysis.metrics import calc_cramers_v, interpret_effect_size\n",
    "from src.analysis.constants import PHASE_ORDER_CLINICAL, COHORT_BINS, COHORT_LABELS\n",
    "\n",
    "# Paths (validated at setup)\n",
    "DB_PATH = PROJECT_ROOT / 'data' / 'database' / 'clinical_trials.db'\n",
    "SQL_PATH = PROJECT_ROOT / 'sql' / 'queries'\n",
    "assert DB_PATH.exists(), f\"DB not found: {DB_PATH}\"\n",
    "assert SQL_PATH.exists(), f\"SQL folder not found: {SQL_PATH}\"\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Database connection\n",
    "# ============================================================\n",
    "\n",
    "conn = get_db_connection(DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Loading & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1.1 Load ABT (study-level with geographic features)\n",
    "# ============================================================\n",
    "\n",
    "df_abt = load_sql_query('q4_abt.sql', conn, SQL_PATH)\n",
    "\n",
    "n_studies = len(df_abt)\n",
    "n_with_location = df_abt['has_location_data'].sum()\n",
    "pct_location = n_with_location / n_studies * 100\n",
    "year_min, year_max = df_abt['start_year'].min(), df_abt['start_year'].max()\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "**ABT:** {n_studies:,} studies ({year_min}–{year_max}). Location data: {n_with_location:,} ({pct_location:.0f}%).\n",
    "\"\"\"))\n",
    "\n",
    "# Filter to studies with location data\n",
    "df_geo = df_abt[df_abt['has_location_data'] == 1].copy()\n",
    "n_geo = len(df_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Geographic summary (n = 88,404 studies with location data):**\n",
       "\n",
       "| Metric | Value |\n",
       "|--------|-------|\n",
       "| Unique countries | 175 |\n",
       "| Single-site trials | 64,557 (73.0%) |\n",
       "| Multinational trials | 7,196 (8.1%) |\n",
       "| Large multi-site (≥10 sites) | 8,959 (10.1%) |\n",
       "| Median sites per trial | 1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1.2 Geographic summary statistics\n",
    "# ============================================================\n",
    "\n",
    "# Unique countries\n",
    "n_countries = df_geo['primary_country'].nunique()\n",
    "\n",
    "# Site complexity distribution\n",
    "n_single_site = df_geo['is_single_site'].sum()\n",
    "n_multinational = df_geo['is_multinational'].sum()\n",
    "n_large_multisite = df_geo['is_large_multisite'].sum()\n",
    "\n",
    "pct_single = n_single_site / n_geo * 100\n",
    "pct_multinational = n_multinational / n_geo * 100\n",
    "pct_large = n_large_multisite / n_geo * 100\n",
    "\n",
    "# Site count statistics\n",
    "median_sites = df_geo['n_sites'].median()\n",
    "mean_sites = df_geo['n_sites'].mean()\n",
    "max_sites = df_geo['n_sites'].max()\n",
    "q75_sites = df_geo['n_sites'].quantile(0.75)\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "**Geographic summary (n = {n_geo:,} studies with location data):**\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Unique countries | {n_countries:,} |\n",
    "| Single-site trials | {n_single_site:,} ({pct_single:.1f}%) |\n",
    "| Multinational trials | {n_multinational:,} ({pct_multinational:.1f}%) |\n",
    "| Large multi-site (≥10 sites) | {n_large_multisite:,} ({pct_large:.1f}%) |\n",
    "| Median sites per trial | {median_sites:.0f} |\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Geographic Distribution\n",
    "\n",
    "**Question:** Where are clinical trials conducted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2.1 Country-level distribution\n",
    "# ============================================================\n",
    "\n",
    "# Aggregate by primary country\n",
    "df_country = (\n",
    "    df_geo\n",
    "    .groupby('primary_country')\n",
    "    .agg(\n",
    "        n_trials=('study_id', 'nunique'),\n",
    "        n_interventional=('is_interventional', 'sum'),\n",
    "        n_industry=('is_industry_sponsor', 'sum'),\n",
    "        median_sites=('n_sites', 'median'),\n",
    "        pct_multinational=('is_multinational', 'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values('n_trials', ascending=False)\n",
    ")\n",
    "df_country['pct_multinational'] = df_country['pct_multinational'] * 100\n",
    "df_country['pct_interventional'] = df_country['n_interventional'] / df_country['n_trials'] * 100\n",
    "df_country['pct_industry'] = df_country['n_industry'] / df_country['n_trials'] * 100\n",
    "\n",
    "# Top 20 countries\n",
    "top20 = df_country.head(20).copy()\n",
    "\n",
    "# Concentration metrics (trial-weighted, primary country assignment)\n",
    "total_trials = df_country['n_trials'].sum()\n",
    "top5_share = df_country.head(5)['n_trials'].sum() / total_trials * 100\n",
    "top10_share = df_country.head(10)['n_trials'].sum() / total_trials * 100\n",
    "\n",
    "# HHI (Herfindahl-Hirschman Index) with bootstrap CI\n",
    "df_country['market_share'] = df_country['n_trials'] / total_trials\n",
    "hhi = (df_country['market_share'] ** 2).sum() * 10000\n",
    "\n",
    "# Bootstrap confidence interval for HHI\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 1000\n",
    "country_array = df_geo['primary_country'].values\n",
    "hhi_bootstrap = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    sample_idx = np.random.choice(len(country_array), size=len(country_array), replace=True)\n",
    "    sample_countries = country_array[sample_idx]\n",
    "    counts = pd.Series(sample_countries).value_counts()\n",
    "    shares = counts / counts.sum()\n",
    "    hhi_boot = (shares ** 2).sum() * 10000\n",
    "    hhi_bootstrap.append(hhi_boot)\n",
    "\n",
    "hhi_ci_low = np.percentile(hhi_bootstrap, 2.5)\n",
    "hhi_ci_high = np.percentile(hhi_bootstrap, 97.5)\n",
    "\n",
    "# HHI interpretation (thresholds: <1500 unconcentrated, 1500-2500 moderate, >2500 high)\n",
    "if hhi < 1500:\n",
    "    hhi_interpretation = \"unconcentrated\"\n",
    "elif hhi < 2500:\n",
    "    hhi_interpretation = \"moderately concentrated\"\n",
    "else:\n",
    "    hhi_interpretation = \"highly concentrated\"\n",
    "\n",
    "ci_spans_boundary = (hhi_ci_low < 1500 < hhi_ci_high) or (hhi_ci_low < 2500 < hhi_ci_high)\n",
    "boundary_note = \" (CI spans threshold)\" if ci_spans_boundary else \"\"\n",
    "\n",
    "pct_multinational_all = df_geo['is_multinational'].mean() * 100\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### 2.1 Geographic concentration (primary country assignment)\n",
    "\n",
    "| Metric | Value | 95% CI |\n",
    "|--------|-------|--------|\n",
    "| Top 5 countries | {top5_share:.0f}% | — |\n",
    "| Top 10 countries | {top10_share:.0f}% | — |\n",
    "| **HHI** | **{hhi:.0f}** ({hhi_interpretation}) | [{hhi_ci_low:.0f}, {hhi_ci_high:.0f}]{boundary_note} |\n",
    "\n",
    "**Interpretation caveat:** {pct_multinational_all:.0f}% of trials are multinational but assigned to a single country (mode of sites). This inflates top-market shares and HHI. See §2.1.2 for site-weighted alternative.\n",
    "\"\"\"))\n",
    "\n",
    "display(Markdown(\"**Top 20 countries by trial count:**\"))\n",
    "display(\n",
    "    top20[['primary_country', 'n_trials', 'pct_interventional', 'pct_industry', 'median_sites']]\n",
    "    .rename(columns={\n",
    "        'primary_country': 'Country',\n",
    "        'n_trials': 'Trials',\n",
    "        'pct_interventional': 'Interventional %',\n",
    "        'pct_industry': 'Industry %',\n",
    "        'median_sites': 'Median Sites',\n",
    "    })\n",
    "    .style.format({\n",
    "        'Trials': '{:,.0f}',\n",
    "        'Interventional %': '{:.1f}%',\n",
    "        'Industry %': '{:.1f}%',\n",
    "        'Median Sites': '{:.0f}',\n",
    "    }).hide(axis='index')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pwvk974y1i",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### 2.1.1 Sensitivity: Single-country trials only\n",
       "\n",
       "| Metric | All | Single-country | Δ [95% CI] |\n",
       "|--------|-----|----------------|------------|\n",
       "| N | 88,404 | 81,208 | — |\n",
       "| HHI | 1504 | 1423 | +82 [+52, +108] |\n",
       "\n",
       "ΔHHI excludes zero. Classification changes (moderately concentrated → unconcentrated).\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2.1.1 Sensitivity: Single-country trials only\n",
    "# ============================================================\n",
    "\n",
    "df_single_country = df_geo[df_geo['is_multinational'] == 0].copy()\n",
    "n_single = len(df_single_country)\n",
    "\n",
    "single_country_counts = df_single_country['primary_country'].value_counts()\n",
    "single_total = single_country_counts.sum()\n",
    "single_shares = single_country_counts / single_total\n",
    "hhi_single = (single_shares ** 2).sum() * 10000\n",
    "top5_single_share = single_country_counts.head(5).sum() / single_total * 100\n",
    "\n",
    "if hhi_single < 1500:\n",
    "    hhi_single_interp = \"unconcentrated\"\n",
    "elif hhi_single < 2500:\n",
    "    hhi_single_interp = \"moderately concentrated\"\n",
    "else:\n",
    "    hhi_single_interp = \"highly concentrated\"\n",
    "\n",
    "hhi_delta = hhi - hhi_single\n",
    "\n",
    "# Bootstrap CI for delta\n",
    "np.random.seed(43)\n",
    "single_country_array = df_single_country['primary_country'].values\n",
    "hhi_delta_bootstrap = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    sample_all = country_array[np.random.choice(len(country_array), len(country_array), replace=True)]\n",
    "    shares_all = pd.Series(sample_all).value_counts() / len(sample_all)\n",
    "    hhi_all_boot = (shares_all ** 2).sum() * 10000\n",
    "    \n",
    "    sample_single = single_country_array[np.random.choice(len(single_country_array), len(single_country_array), replace=True)]\n",
    "    shares_single = pd.Series(sample_single).value_counts() / len(sample_single)\n",
    "    hhi_single_boot = (shares_single ** 2).sum() * 10000\n",
    "    \n",
    "    hhi_delta_bootstrap.append(hhi_all_boot - hhi_single_boot)\n",
    "\n",
    "hhi_delta_ci_low = np.percentile(hhi_delta_bootstrap, 2.5)\n",
    "hhi_delta_ci_high = np.percentile(hhi_delta_bootstrap, 97.5)\n",
    "delta_significant = not (hhi_delta_ci_low <= 0 <= hhi_delta_ci_high)\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### 2.1.1 Sensitivity: Single-country trials only\n",
    "\n",
    "| Metric | All | Single-country | Δ [95% CI] |\n",
    "|--------|-----|----------------|------------|\n",
    "| N | {n_geo:,} | {n_single:,} | — |\n",
    "| HHI | {hhi:.0f} | {hhi_single:.0f} | {hhi_delta:+.0f} [{hhi_delta_ci_low:+.0f}, {hhi_delta_ci_high:+.0f}] |\n",
    "\n",
    "ΔHHI {'excludes' if delta_significant else 'includes'} zero. Classification {'changes' if hhi_interpretation != hhi_single_interp else 'unchanged'} ({hhi_interpretation} → {hhi_single_interp}).\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlgnh6lu06m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2.1.2 Site-weighted concentration (fractional assignment)\n",
    "# ============================================================\n",
    "\n",
    "# Each site contributes 1/n_sites to its country\n",
    "query_site_weighted = \"\"\"\n",
    "WITH site_contributions AS (\n",
    "    SELECT \n",
    "        l.study_id,\n",
    "        l.country,\n",
    "        1.0 / COUNT(*) OVER (PARTITION BY l.study_id) AS fractional_weight\n",
    "    FROM locations l\n",
    "    JOIN v_studies_clean s ON l.study_id = s.study_id\n",
    "    WHERE l.country IS NOT NULL AND l.country != ''\n",
    "      AND s.is_start_year_in_scope = 1\n",
    ")\n",
    "SELECT \n",
    "    country,\n",
    "    SUM(fractional_weight) AS weighted_trials,\n",
    "    COUNT(DISTINCT study_id) AS n_trials_any_site\n",
    "FROM site_contributions\n",
    "GROUP BY country\n",
    "ORDER BY weighted_trials DESC\n",
    "\"\"\"\n",
    "\n",
    "df_site_weighted = pd.read_sql(query_site_weighted, conn)\n",
    "\n",
    "# Calculate site-weighted HHI\n",
    "total_weighted = df_site_weighted['weighted_trials'].sum()\n",
    "df_site_weighted['market_share'] = df_site_weighted['weighted_trials'] / total_weighted\n",
    "hhi_site_weighted = (df_site_weighted['market_share'] ** 2).sum() * 10000\n",
    "\n",
    "top5_site_share = df_site_weighted.head(5)['weighted_trials'].sum() / total_weighted * 100\n",
    "top10_site_share = df_site_weighted.head(10)['weighted_trials'].sum() / total_weighted * 100\n",
    "\n",
    "# Bootstrap CI for site-weighted HHI\n",
    "np.random.seed(45)\n",
    "hhi_site_bootstrap = []\n",
    "\n",
    "# Get site-level data for bootstrap\n",
    "df_sites_boot = pd.read_sql(\"\"\"\n",
    "    SELECT l.study_id, l.country\n",
    "    FROM locations l\n",
    "    JOIN v_studies_clean s ON l.study_id = s.study_id\n",
    "    WHERE l.country IS NOT NULL AND l.country != ''\n",
    "      AND s.is_start_year_in_scope = 1\n",
    "\"\"\", conn)\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    # Sample studies with replacement\n",
    "    unique_studies = df_sites_boot['study_id'].unique()\n",
    "    sampled_studies = np.random.choice(unique_studies, size=len(unique_studies), replace=True)\n",
    "    boot_data = df_sites_boot[df_sites_boot['study_id'].isin(sampled_studies)].copy()\n",
    "    \n",
    "    # Calculate fractional weights per study\n",
    "    site_counts = boot_data.groupby('study_id').size()\n",
    "    boot_data['weight'] = boot_data['study_id'].map(lambda x: 1.0 / site_counts.get(x, 1))\n",
    "    \n",
    "    # Aggregate by country\n",
    "    country_weighted = boot_data.groupby('country')['weight'].sum()\n",
    "    shares = country_weighted / country_weighted.sum()\n",
    "    hhi_boot = (shares ** 2).sum() * 10000\n",
    "    hhi_site_bootstrap.append(hhi_boot)\n",
    "\n",
    "hhi_site_ci_low = np.percentile(hhi_site_bootstrap, 2.5)\n",
    "hhi_site_ci_high = np.percentile(hhi_site_bootstrap, 97.5)\n",
    "\n",
    "if hhi_site_weighted < 1500:\n",
    "    hhi_site_interp = \"unconcentrated\"\n",
    "elif hhi_site_weighted < 2500:\n",
    "    hhi_site_interp = \"moderately concentrated\"\n",
    "else:\n",
    "    hhi_site_interp = \"highly concentrated\"\n",
    "\n",
    "hhi_delta_method = hhi - hhi_site_weighted\n",
    "top5_delta = top5_share - top5_site_share\n",
    "classification_change = hhi_interpretation != hhi_site_interp\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### 2.1.2 Site-weighted concentration\n",
    "\n",
    "A trial with sites in 3 countries gives 1/3 credit to each, rather than assigning the full trial to one country.\n",
    "\n",
    "| Metric | Primary Country | Site-Weighted | Δ |\n",
    "|--------|-----------------|---------------|---|\n",
    "| Top 5 | {top5_share:.0f}% | {top5_site_share:.0f}% | {top5_delta:+.0f}pp |\n",
    "| Top 10 | {top10_share:.0f}% | {top10_site_share:.0f}% | {top10_share - top10_site_share:+.0f}pp |\n",
    "| **HHI** | **{hhi:.0f}** [{hhi_ci_low:.0f}, {hhi_ci_high:.0f}] | **{hhi_site_weighted:.0f}** [{hhi_site_ci_low:.0f}, {hhi_site_ci_high:.0f}] | **{hhi_delta_method:+.0f}** |\n",
    "| Classification | {hhi_interpretation} | {hhi_site_interp} | {'differs' if classification_change else 'consistent'} |\n",
    "\n",
    "**Limitation:** Site-weighted counts participation, not capacity. Neither method captures enrollment volume.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": "<b>%{y}</b><br>Trials: %{x:,}<extra></extra>",
         "marker": {
          "color": [
           "rgb(241, 245, 249)",
           "rgb(241, 245, 249)",
           "rgb(240, 244, 249)",
           "rgb(239, 244, 249)",
           "rgb(235, 241, 249)",
           "rgb(235, 240, 249)",
           "rgb(233, 239, 248)",
           "rgb(231, 238, 248)",
           "rgb(231, 238, 248)",
           "rgb(229, 237, 248)",
           "rgb(228, 236, 248)",
           "rgb(227, 235, 248)",
           "rgb(214, 226, 247)",
           "rgb(197, 214, 246)",
           "rgb(37, 99, 235)"
          ]
         },
         "orientation": "h",
         "text": [
          "1,238",
          "1,290",
          "1,451",
          "1,487",
          "2,142",
          "2,186",
          "2,504",
          "2,664",
          "2,689",
          "2,996",
          "3,212",
          "3,274",
          "5,254",
          "7,780",
          "31,791"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": {
          "bdata": "1gQKBasFzwVeCIoIyAloCoEKtAuMDMoMhhRkHi98",
          "dtype": "i2"
         },
         "y": [
          "Brazil",
          "Netherlands",
          "Taiwan",
          "Denmark",
          "South Korea",
          "Spain",
          "Italy",
          "Germany",
          "Egypt",
          "United Kingdom",
          "Canada",
          "Turkey (Türkiye)",
          "France",
          "China",
          "United States"
         ]
        }
       ],
       "layout": {
        "bargap": 0.22,
        "font": {
         "color": "#374151",
         "family": "Arial"
        },
        "height": 500,
        "margin": {
         "b": 50,
         "l": 180,
         "r": 180,
         "t": 80
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>Top 15 Countries by Trial Count</b><br><span style='font-size:12px; color:#6b7280'>United States: 31,791 | China: 7,780</span>",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "rangemode": "tozero",
         "showgrid": false,
         "showticklabels": false,
         "title": {}
        },
        "yaxis": {
         "autorange": "reversed",
         "tickfont": {
          "size": 12
         },
         "title": {}
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2.2 Country distribution chart\n",
    "# ============================================================\n",
    "\n",
    "# Prepare data for plot (sorted ascending for horizontal bar - largest at top)\n",
    "plot_data = top20.sort_values('n_trials', ascending=True).tail(15)\n",
    "\n",
    "# Key values for subtitle\n",
    "top1 = df_country.iloc[0]\n",
    "top2 = df_country.iloc[1]\n",
    "\n",
    "fig_country = create_horizontal_bar_chart(\n",
    "    data=plot_data,\n",
    "    value_col='n_trials',\n",
    "    label_col='primary_country',\n",
    "    title='Top 15 Countries by Trial Count',\n",
    "    subtitle=f\"{top1['primary_country']}: {top1['n_trials']:,.0f} | {top2['primary_country']}: {top2['n_trials']:,.0f}\",\n",
    "    show_pct=False,\n",
    "    height=500,\n",
    ")\n",
    "fig_country.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Regional Specialization\n",
    "\n",
    "**Question:** Do countries show relative specialization in particular therapeutic areas?\n",
    "\n",
    "**Approach:** Use Location Quotient (LQ) to measure over-/under-representation of conditions by country.\n",
    "\n",
    "$$LQ = \\frac{\\text{share of country's trials in condition}}{\\text{share of global trials in condition}}$$\n",
    "\n",
    "- **LQ > 1.5**: Country relatively specialized (over-represented)\n",
    "- **LQ ≈ 1**: Country matches global distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3.1 Load country × condition data for specialization analysis\n",
    "# ============================================================\n",
    "\n",
    "df_spec = load_sql_query('q4_country_condition.sql', conn, SQL_PATH)\n",
    "\n",
    "n_combinations = len(df_spec)\n",
    "n_countries_spec = df_spec['country'].nunique()\n",
    "n_conditions_spec = df_spec['condition_standardized'].nunique()\n",
    "\n",
    "# Quantify multi-condition trials\n",
    "median_conds_per_trial = df_geo['n_conditions'].median()\n",
    "mean_conds_per_trial = df_geo['n_conditions'].mean()\n",
    "pct_multi_condition = (df_geo['n_conditions'] > 1).mean() * 100\n",
    "\n",
    "# Quantify condition fragmentation\n",
    "top_conditions = df_spec.groupby('condition_standardized')['n_trials'].sum().nlargest(50)\n",
    "top50_trials = top_conditions.sum()\n",
    "total_condition_trials = df_spec.groupby('condition_standardized')['n_trials'].sum().sum()\n",
    "top50_coverage = top50_trials / total_condition_trials * 100\n",
    "\n",
    "condition_prefixes = df_spec['condition_standardized'].str[:10].value_counts()\n",
    "n_potential_synonyms = (condition_prefixes > 1).sum()\n",
    "pct_fragmented = n_potential_synonyms / len(condition_prefixes) * 100\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### 3.1 Specialization data\n",
    "\n",
    "{n_combinations:,} country × condition pairs from {n_countries_spec} countries and {n_conditions_spec:,} conditions.\n",
    "\n",
    "**Filters:** Countries ≥50 trials, conditions ≥100 global trials, pairs ≥5 trials.\n",
    "\n",
    "| Characteristic | Value |\n",
    "|----------------|-------|\n",
    "| Multi-condition trials | {pct_multi_condition:.0f}% |\n",
    "| Top-50 conditions coverage | {top50_coverage:.0f}% |\n",
    "| Prefix fragmentation (synonyms) | ~{pct_fragmented:.0f}% |\n",
    "\n",
    "*Multi-condition trials inflate LQ denominators. LQ does not control for phase or sponsor. See §3.2.1–3.2.3 for sensitivity analyses.*\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3.2 Identify apparent specializations (LQ > 1.5)\n",
    "# ============================================================\n",
    "\n",
    "df_high_lq = df_spec[df_spec['location_quotient'] > 1.5].copy()\n",
    "df_high_lq = df_high_lq.sort_values('location_quotient', ascending=False)\n",
    "\n",
    "major_countries = ['United States', 'China', 'Germany', 'France', 'United Kingdom', 'Japan', 'Canada', 'Italy', 'Spain', 'India']\n",
    "\n",
    "specializations = []\n",
    "for country in major_countries:\n",
    "    country_data = df_high_lq[df_high_lq['country'] == country].head(3)\n",
    "    if len(country_data) > 0:\n",
    "        specs = []\n",
    "        for _, row in country_data.iterrows():\n",
    "            lq = row['location_quotient']\n",
    "            n = row['n_trials']\n",
    "            specs.append(f\"{row['condition_standardized'][:30]} (LQ={lq:.1f}, n={n:,.0f})\")\n",
    "        specializations.append({\n",
    "            'Country': country,\n",
    "            'Apparent Specializations (LQ > 1.5)': ', '.join(specs),\n",
    "        })\n",
    "\n",
    "df_spec_summary = pd.DataFrame(specializations)\n",
    "\n",
    "display(Markdown(\"### 3.2 Apparent specializations by country\"))\n",
    "display(Markdown(\"*LQ > 1.5 indicates over-representation, not expertise. See validations below.*\"))\n",
    "display(df_spec_summary.style.hide(axis='index'))\n",
    "\n",
    "# ============================================================\n",
    "# 3.2.1 Single-condition sensitivity: impact of multi-condition trials\n",
    "# ============================================================\n",
    "\n",
    "display(Markdown(\"### 3.2.1 Multi-condition inflation sensitivity\"))\n",
    "\n",
    "# Quantify multi-condition impact\n",
    "multi_cond_trials = df_geo[df_geo['n_conditions'] > 1]\n",
    "single_cond_trials = df_geo[df_geo['n_conditions'] == 1]\n",
    "n_multi = len(multi_cond_trials)\n",
    "n_single = len(single_cond_trials)\n",
    "pct_multi = n_multi / len(df_geo) * 100\n",
    "\n",
    "# Query LQ using only single-condition trials (no denominator inflation)\n",
    "query_single_cond_lq = \"\"\"\n",
    "WITH \n",
    "single_cond_studies AS (\n",
    "    SELECT c.study_id, LOWER(TRIM(c.condition_name)) AS condition_standardized\n",
    "    FROM conditions c\n",
    "    JOIN v_studies_clean s ON c.study_id = s.study_id\n",
    "    WHERE c.condition_name IS NOT NULL AND TRIM(c.condition_name) != ''\n",
    "      AND s.is_start_year_in_scope = 1\n",
    "    GROUP BY c.study_id\n",
    "    HAVING COUNT(DISTINCT LOWER(TRIM(c.condition_name))) = 1\n",
    "),\n",
    "single_study_countries AS (\n",
    "    SELECT DISTINCT l.study_id, l.country, sc.condition_standardized\n",
    "    FROM locations l\n",
    "    JOIN single_cond_studies sc ON l.study_id = sc.study_id\n",
    "    JOIN v_studies_clean s ON l.study_id = s.study_id\n",
    "    WHERE l.country IS NOT NULL AND l.country != ''\n",
    "      AND s.is_start_year_in_scope = 1\n",
    "),\n",
    "single_country_condition AS (\n",
    "    SELECT country, condition_standardized, COUNT(DISTINCT study_id) AS n_trials\n",
    "    FROM single_study_countries GROUP BY country, condition_standardized\n",
    "),\n",
    "single_country_totals AS (\n",
    "    SELECT country, COUNT(DISTINCT study_id) AS country_total\n",
    "    FROM single_study_countries GROUP BY country\n",
    "),\n",
    "single_condition_totals AS (\n",
    "    SELECT condition_standardized, COUNT(DISTINCT study_id) AS condition_total\n",
    "    FROM single_study_countries GROUP BY condition_standardized\n",
    "),\n",
    "single_global AS (\n",
    "    SELECT COUNT(DISTINCT study_id) AS global_total FROM single_study_countries\n",
    ")\n",
    "SELECT \n",
    "    scc.country, scc.condition_standardized, scc.n_trials,\n",
    "    sct.country_total, scond.condition_total, sg.global_total,\n",
    "    ROUND((CAST(scc.n_trials AS REAL) / sct.country_total) / \n",
    "          (CAST(scond.condition_total AS REAL) / sg.global_total), 3) AS lq_single\n",
    "FROM single_country_condition scc\n",
    "JOIN single_country_totals sct ON scc.country = sct.country\n",
    "JOIN single_condition_totals scond ON scc.condition_standardized = scond.condition_standardized\n",
    "CROSS JOIN single_global sg\n",
    "WHERE sct.country_total >= 30 AND scond.condition_total >= 50 AND scc.n_trials >= 3\n",
    "\"\"\"\n",
    "\n",
    "df_single_lq = pd.read_sql(query_single_cond_lq, conn)\n",
    "\n",
    "# Compare top specializations: all-trial LQ vs single-condition LQ\n",
    "single_validation = []\n",
    "for country in major_countries[:5]:\n",
    "    country_top_full = df_high_lq[df_high_lq['country'] == country].head(1)\n",
    "    if len(country_top_full) == 0:\n",
    "        continue\n",
    "    \n",
    "    top_cond = country_top_full.iloc[0]['condition_standardized']\n",
    "    full_lq = country_top_full.iloc[0]['location_quotient']\n",
    "    full_n = country_top_full.iloc[0]['n_trials']\n",
    "    \n",
    "    single_match = df_single_lq[\n",
    "        (df_single_lq['country'] == country) & \n",
    "        (df_single_lq['condition_standardized'] == top_cond)\n",
    "    ]\n",
    "    \n",
    "    if len(single_match) > 0:\n",
    "        single_lq = single_match.iloc[0]['lq_single']\n",
    "        single_n = single_match.iloc[0]['n_trials']\n",
    "        lq_delta = single_lq - full_lq\n",
    "        lq_delta_pct = (lq_delta / full_lq * 100) if full_lq > 0 else 0\n",
    "        \n",
    "        single_validation.append({\n",
    "            'Country': country,\n",
    "            'Condition': top_cond[:22] + '...' if len(top_cond) > 22 else top_cond,\n",
    "            'All LQ': f\"{full_lq:.2f}\",\n",
    "            'Single-cond LQ': f\"{single_lq:.2f}\",\n",
    "            'Δ': f\"{lq_delta:+.2f} ({lq_delta_pct:+.0f}%)\",\n",
    "        })\n",
    "    else:\n",
    "        single_validation.append({\n",
    "            'Country': country,\n",
    "            'Condition': top_cond[:22] + '...' if len(top_cond) > 22 else top_cond,\n",
    "            'All LQ': f\"{full_lq:.2f}\",\n",
    "            'Single-cond LQ': '—',\n",
    "            'Δ': 'insufficient',\n",
    "        })\n",
    "\n",
    "if single_validation:\n",
    "    df_single_val = pd.DataFrame(single_validation)\n",
    "    display(df_single_val.style.hide(axis='index'))\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "Multi-condition trials = {pct_multi:.0f}% of data. Single-condition LQ excludes these, removing denominator inflation. Large Δ (>±20%) suggests the specialization may be driven by co-occurring conditions rather than primary focus.\n",
    "\"\"\"))\n",
    "\n",
    "# ============================================================\n",
    "# 3.2.2 Phase-stratified LQ sensitivity\n",
    "# ============================================================\n",
    "\n",
    "display(Markdown(\"### 3.2.2 Phase-stratified LQ (Phase 3 only)\"))\n",
    "display(Markdown(\"*Checks if specialization persists when controlling for phase mix.*\"))\n",
    "\n",
    "query_phase3_lq = \"\"\"\n",
    "WITH \n",
    "p3_study_countries AS (\n",
    "    SELECT DISTINCT l.study_id, l.country\n",
    "    FROM locations l\n",
    "    JOIN v_studies_clean s ON l.study_id = s.study_id\n",
    "    WHERE l.country IS NOT NULL AND l.country != ''\n",
    "      AND s.is_start_year_in_scope = 1\n",
    "      AND s.phase = 'PHASE3'\n",
    "),\n",
    "p3_study_conditions AS (\n",
    "    SELECT DISTINCT c.study_id, LOWER(TRIM(c.condition_name)) AS condition_standardized\n",
    "    FROM conditions c\n",
    "    JOIN v_studies_clean s ON c.study_id = s.study_id\n",
    "    WHERE c.condition_name IS NOT NULL AND TRIM(c.condition_name) != ''\n",
    "      AND s.is_start_year_in_scope = 1\n",
    "      AND s.phase = 'PHASE3'\n",
    "),\n",
    "p3_country_condition AS (\n",
    "    SELECT sc.country, scond.condition_standardized, COUNT(DISTINCT sc.study_id) AS n_trials\n",
    "    FROM p3_study_countries sc\n",
    "    JOIN p3_study_conditions scond ON sc.study_id = scond.study_id\n",
    "    GROUP BY sc.country, scond.condition_standardized\n",
    "),\n",
    "p3_country_totals AS (\n",
    "    SELECT country, COUNT(DISTINCT study_id) AS country_total\n",
    "    FROM p3_study_countries GROUP BY country\n",
    "),\n",
    "p3_condition_totals AS (\n",
    "    SELECT condition_standardized, COUNT(DISTINCT study_id) AS condition_total\n",
    "    FROM p3_study_conditions GROUP BY condition_standardized\n",
    "),\n",
    "p3_global AS (\n",
    "    SELECT COUNT(DISTINCT sc.study_id) AS global_total\n",
    "    FROM p3_study_countries sc\n",
    "    JOIN p3_study_conditions scond ON sc.study_id = scond.study_id\n",
    ")\n",
    "SELECT \n",
    "    pcc.country, pcc.condition_standardized, pcc.n_trials,\n",
    "    pct.country_total, pcond.condition_total, pg.global_total,\n",
    "    ROUND((CAST(pcc.n_trials AS REAL) / pct.country_total) / \n",
    "          (CAST(pcond.condition_total AS REAL) / pg.global_total), 3) AS lq_p3\n",
    "FROM p3_country_condition pcc\n",
    "JOIN p3_country_totals pct ON pcc.country = pct.country\n",
    "JOIN p3_condition_totals pcond ON pcc.condition_standardized = pcond.condition_standardized\n",
    "CROSS JOIN p3_global pg\n",
    "WHERE pct.country_total >= 20 AND pcond.condition_total >= 30 AND pcc.n_trials >= 3\n",
    "\"\"\"\n",
    "\n",
    "df_p3_spec = pd.read_sql(query_phase3_lq, conn)\n",
    "\n",
    "phase_validation = []\n",
    "for country in major_countries[:5]:\n",
    "    country_top_full = df_high_lq[df_high_lq['country'] == country].head(1)\n",
    "    if len(country_top_full) == 0:\n",
    "        continue\n",
    "    \n",
    "    top_cond = country_top_full.iloc[0]['condition_standardized']\n",
    "    full_lq = country_top_full.iloc[0]['location_quotient']\n",
    "    \n",
    "    p3_match = df_p3_spec[\n",
    "        (df_p3_spec['country'] == country) & \n",
    "        (df_p3_spec['condition_standardized'] == top_cond)\n",
    "    ]\n",
    "    \n",
    "    if len(p3_match) > 0:\n",
    "        p3_lq = p3_match.iloc[0]['lq_p3']\n",
    "        p3_n = p3_match.iloc[0]['n_trials']\n",
    "        lq_delta = p3_lq - full_lq\n",
    "        \n",
    "        phase_validation.append({\n",
    "            'Country': country,\n",
    "            'Condition': top_cond[:22] + '...' if len(top_cond) > 22 else top_cond,\n",
    "            'All-phase LQ': f\"{full_lq:.2f}\",\n",
    "            'Phase 3 LQ': f\"{p3_lq:.2f}\",\n",
    "            'Δ': f\"{lq_delta:+.2f}\",\n",
    "            'P3 n': f\"{p3_n:,}\",\n",
    "        })\n",
    "    else:\n",
    "        phase_validation.append({\n",
    "            'Country': country,\n",
    "            'Condition': top_cond[:22] + '...' if len(top_cond) > 22 else top_cond,\n",
    "            'All-phase LQ': f\"{full_lq:.2f}\",\n",
    "            'Phase 3 LQ': '—',\n",
    "            'Δ': 'insufficient',\n",
    "            'P3 n': '—',\n",
    "        })\n",
    "\n",
    "if phase_validation:\n",
    "    df_phase_val = pd.DataFrame(phase_validation)\n",
    "    display(df_phase_val.style.hide(axis='index'))\n",
    "    display(Markdown(\"*Δ > ±0.3 suggests phase-specific pattern.*\"))\n",
    "\n",
    "# ============================================================\n",
    "# 3.2.3 Temporal LQ validation: 2015+ vs full period\n",
    "# ============================================================\n",
    "\n",
    "display(Markdown(\"### 3.2.3 Temporal LQ validation (2015+ vs full period)\"))\n",
    "display(Markdown(\"*Checks if historical patterns persist in recent data.*\"))\n",
    "\n",
    "query_recent = \"\"\"\n",
    "WITH \n",
    "recent_study_countries AS (\n",
    "    SELECT DISTINCT l.study_id, l.country\n",
    "    FROM locations l\n",
    "    JOIN v_studies_clean s ON l.study_id = s.study_id\n",
    "    WHERE l.country IS NOT NULL AND l.country != ''\n",
    "      AND s.start_year >= 2015\n",
    "      AND s.is_start_year_in_scope = 1\n",
    "),\n",
    "recent_study_conditions AS (\n",
    "    SELECT DISTINCT c.study_id, LOWER(TRIM(c.condition_name)) AS condition_standardized\n",
    "    FROM conditions c\n",
    "    JOIN v_studies_clean s ON c.study_id = s.study_id\n",
    "    WHERE c.condition_name IS NOT NULL AND TRIM(c.condition_name) != ''\n",
    "      AND s.start_year >= 2015\n",
    "      AND s.is_start_year_in_scope = 1\n",
    "),\n",
    "recent_country_condition AS (\n",
    "    SELECT sc.country, scond.condition_standardized, COUNT(DISTINCT sc.study_id) AS n_trials\n",
    "    FROM recent_study_countries sc\n",
    "    JOIN recent_study_conditions scond ON sc.study_id = scond.study_id\n",
    "    GROUP BY sc.country, scond.condition_standardized\n",
    "),\n",
    "recent_country_totals AS (\n",
    "    SELECT country, COUNT(DISTINCT study_id) AS country_total\n",
    "    FROM recent_study_countries GROUP BY country\n",
    "),\n",
    "recent_condition_totals AS (\n",
    "    SELECT condition_standardized, COUNT(DISTINCT study_id) AS condition_total\n",
    "    FROM recent_study_conditions GROUP BY condition_standardized\n",
    "),\n",
    "recent_global AS (\n",
    "    SELECT COUNT(DISTINCT sc.study_id) AS global_total\n",
    "    FROM recent_study_countries sc\n",
    "    JOIN recent_study_conditions scond ON sc.study_id = scond.study_id\n",
    ")\n",
    "SELECT \n",
    "    rcc.country, rcc.condition_standardized, rcc.n_trials,\n",
    "    rct.country_total, rcond.condition_total, rg.global_total,\n",
    "    ROUND((CAST(rcc.n_trials AS REAL) / rct.country_total) / \n",
    "          (CAST(rcond.condition_total AS REAL) / rg.global_total), 3) AS lq_recent\n",
    "FROM recent_country_condition rcc\n",
    "JOIN recent_country_totals rct ON rcc.country = rct.country\n",
    "JOIN recent_condition_totals rcond ON rcc.condition_standardized = rcond.condition_standardized\n",
    "CROSS JOIN recent_global rg\n",
    "WHERE rct.country_total >= 30 AND rcond.condition_total >= 50 AND rcc.n_trials >= 3\n",
    "\"\"\"\n",
    "\n",
    "df_recent_spec = pd.read_sql(query_recent, conn)\n",
    "\n",
    "temporal_validation = []\n",
    "for country in major_countries[:5]:\n",
    "    country_top_full = df_high_lq[df_high_lq['country'] == country].head(1)\n",
    "    if len(country_top_full) == 0:\n",
    "        continue\n",
    "    \n",
    "    top_cond = country_top_full.iloc[0]['condition_standardized']\n",
    "    full_lq = country_top_full.iloc[0]['location_quotient']\n",
    "    \n",
    "    recent_match = df_recent_spec[\n",
    "        (df_recent_spec['country'] == country) & \n",
    "        (df_recent_spec['condition_standardized'] == top_cond)\n",
    "    ]\n",
    "    \n",
    "    if len(recent_match) > 0:\n",
    "        recent_lq = recent_match.iloc[0]['lq_recent']\n",
    "        recent_n = recent_match.iloc[0]['n_trials']\n",
    "        lq_delta = recent_lq - full_lq\n",
    "        lq_delta_pct = (lq_delta / full_lq * 100) if full_lq > 0 else 0\n",
    "        \n",
    "        temporal_validation.append({\n",
    "            'Country': country,\n",
    "            'Condition': top_cond[:22] + '...' if len(top_cond) > 22 else top_cond,\n",
    "            'Full LQ': f\"{full_lq:.2f}\",\n",
    "            '2015+ LQ': f\"{recent_lq:.2f}\",\n",
    "            'ΔLQ': f\"{lq_delta:+.2f} ({lq_delta_pct:+.0f}%)\",\n",
    "        })\n",
    "    else:\n",
    "        temporal_validation.append({\n",
    "            'Country': country,\n",
    "            'Condition': top_cond[:22] + '...' if len(top_cond) > 22 else top_cond,\n",
    "            'Full LQ': f\"{full_lq:.2f}\",\n",
    "            '2015+ LQ': '—',\n",
    "            'ΔLQ': 'insufficient',\n",
    "        })\n",
    "\n",
    "if temporal_validation:\n",
    "    df_temporal = pd.DataFrame(temporal_validation)\n",
    "    display(df_temporal.style.hide(axis='index'))\n",
    "    display(Markdown(\"*ΔLQ > ±20% suggests historical patterns may not reflect current activity.*\"))\n",
    "\n",
    "# Threshold sensitivity\n",
    "thresholds = [1.5, 2.0, 2.5]\n",
    "sensitivity = [len(df_spec[df_spec['location_quotient'] > t]) for t in thresholds]\n",
    "display(Markdown(f\"**Threshold sensitivity:** LQ>1.5: {sensitivity[0]:,} | LQ>2.0: {sensitivity[1]:,} | LQ>2.5: {sensitivity[2]:,} pairs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7nsj0q93wh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3.2.3 LQ Heatmap: Top countries × Top conditions\n",
    "# ============================================================\n",
    "\n",
    "# Prepare data for heatmap: top 8 countries × top 12 conditions\n",
    "top8_countries = df_country.head(8)['primary_country'].tolist()\n",
    "top12_conditions = (\n",
    "    df_spec\n",
    "    .groupby('condition_standardized')['n_trials'].sum()\n",
    "    .nlargest(12)\n",
    "    .index.tolist()\n",
    ")\n",
    "\n",
    "# Filter and pivot for LQ values\n",
    "df_heatmap_raw = df_spec[\n",
    "    (df_spec['country'].isin(top8_countries)) &\n",
    "    (df_spec['condition_standardized'].isin(top12_conditions))\n",
    "].pivot_table(\n",
    "    index='country',\n",
    "    columns='condition_standardized',\n",
    "    values='location_quotient',\n",
    "    fill_value=1.0\n",
    ")\n",
    "\n",
    "# Also pivot for n_trials (sample size)\n",
    "df_n_raw = df_spec[\n",
    "    (df_spec['country'].isin(top8_countries)) &\n",
    "    (df_spec['condition_standardized'].isin(top12_conditions))\n",
    "].pivot_table(\n",
    "    index='country',\n",
    "    columns='condition_standardized',\n",
    "    values='n_trials',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "df_heatmap_raw = df_heatmap_raw.reindex(top8_countries)\n",
    "df_n_raw = df_n_raw.reindex(top8_countries).fillna(0)\n",
    "\n",
    "short_names = {c: c[:20] + '...' if len(c) > 20 else c for c in df_heatmap_raw.columns}\n",
    "df_heatmap = df_heatmap_raw.rename(columns=short_names)\n",
    "\n",
    "# Create text annotations with n indicator for low-sample cells\n",
    "# † = n < 50 (interpret with caution)\n",
    "LOW_N_THRESHOLD = 50\n",
    "text_annotations = []\n",
    "low_n_cells = []\n",
    "for i in range(df_heatmap_raw.shape[0]):\n",
    "    row = []\n",
    "    for j in range(df_heatmap_raw.shape[1]):\n",
    "        raw_val = df_heatmap_raw.values[i, j]\n",
    "        n_val = df_n_raw.values[i, j] if i < df_n_raw.shape[0] and j < df_n_raw.shape[1] else 0\n",
    "        \n",
    "        # Format LQ with n indicator\n",
    "        if n_val < LOW_N_THRESHOLD:\n",
    "            suffix = \"†\"\n",
    "            low_n_cells.append((df_heatmap_raw.index[i], df_heatmap_raw.columns[j][:15], int(n_val), raw_val))\n",
    "        else:\n",
    "            suffix = \"\"\n",
    "        \n",
    "        if raw_val > 2.0:\n",
    "            row.append(f\"{raw_val:.1f}*{suffix}\")\n",
    "        elif raw_val < 0.5:\n",
    "            row.append(f\"{raw_val:.2f}*{suffix}\")\n",
    "        else:\n",
    "            row.append(f\"{raw_val:.1f}{suffix}\")\n",
    "    text_annotations.append(row)\n",
    "\n",
    "min_lq = df_heatmap_raw.values.min()\n",
    "max_lq = df_heatmap_raw.values.max()\n",
    "\n",
    "# Create heatmap\n",
    "fig_heatmap = go.Figure(data=go.Heatmap(\n",
    "    z=np.clip(df_heatmap.values, 0.5, 2.0),\n",
    "    x=list(df_heatmap.columns),\n",
    "    y=list(df_heatmap.index),\n",
    "    colorscale=[\n",
    "        [0, '#2166ac'],\n",
    "        [0.4, '#f7f7f7'],\n",
    "        [0.6, '#f7f7f7'],\n",
    "        [1, '#b2182b']\n",
    "    ],\n",
    "    zmin=0.5,\n",
    "    zmax=2.0,\n",
    "    text=text_annotations,\n",
    "    texttemplate='%{text}',\n",
    "    textfont=dict(size=10),\n",
    "    hovertemplate='<b>%{y}</b> × %{x}<br>LQ = %{z:.2f}<extra></extra>',\n",
    "    colorbar=dict(\n",
    "        title='LQ',\n",
    "        tickvals=[0.5, 1.0, 1.5, 2.0],\n",
    "        ticktext=['≤0.5', '1.0', '1.5', '≥2.0'],\n",
    "    ),\n",
    "))\n",
    "\n",
    "fig_heatmap.update_layout(\n",
    "    title=dict(\n",
    "        text='<b>Location Quotient: Country × Condition</b><br>'\n",
    "             '<span style=\"font-size:11px;color:gray\">Red = over-represented | White = average | Blue = under-represented | †=n<50</span>',\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "    ),\n",
    "    xaxis=dict(title=None, tickangle=45, tickfont=dict(size=10)),\n",
    "    yaxis=dict(title=None, tickfont=dict(size=11)),\n",
    "    height=450,\n",
    "    width=900,\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=120, r=80, t=80, b=120),\n",
    ")\n",
    "\n",
    "fig_heatmap.show()\n",
    "\n",
    "# Notes\n",
    "display(Markdown(f\"\"\"\n",
    "*Scale clamped to 0.5–2.0. Actual range: [{min_lq:.2f}, {max_lq:.1f}].*\n",
    "\n",
    "**† = n < {LOW_N_THRESHOLD}:** These cells have small sample sizes; LQ estimates are unstable.\n",
    "\"\"\"))\n",
    "\n",
    "if low_n_cells:\n",
    "    n_low = len(low_n_cells)\n",
    "    display(Markdown(f\"*{n_low} of {df_heatmap_raw.size} cells have n < {LOW_N_THRESHOLD}.*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### 3.3 LQ vs χ²\n",
       "\n",
       "χ² requires independent observations; here trials map to ~1.8 conditions each, inflating sample size. LQ measures magnitude: LQ=1.5 means 50% over-representation, LQ=2.0 means twice expected share.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3.3 LQ methodology note\n",
    "# ============================================================\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### 3.3 Why LQ instead of χ²?\n",
    "\n",
    "Trials map to ~{mean_conds_per_trial:.1f} conditions on average, violating χ² independence assumption. LQ provides magnitude (over-/under-representation) without inflated p-values.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cqtzdj32pg",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Temporal Trends in Geographic Distribution\n",
    "\n",
    "**Question:** Has the geographic distribution of trials shifted over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oi7e53xmxm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4.1 Temporal trends with distributional shift metrics\n",
    "# ============================================================\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "df_geo['start_cohort'] = pd.cut(df_geo['start_year'], bins=COHORT_BINS, labels=COHORT_LABELS)\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### 4.1 Temporal analysis\n",
    "\n",
    "**Cohorts:** {', '.join(COHORT_LABELS)}\n",
    "\"\"\"))\n",
    "\n",
    "# ============================================================\n",
    "# 4.1.1 Jensen-Shannon Divergence between cohorts\n",
    "# ============================================================\n",
    "\n",
    "all_countries = df_geo['primary_country'].unique()\n",
    "n_categories = len(all_countries)\n",
    "\n",
    "cohort_distributions = {}\n",
    "for cohort in COHORT_LABELS:\n",
    "    cohort_data = df_geo[df_geo['start_cohort'] == cohort]\n",
    "    if len(cohort_data) > 0:\n",
    "        counts = cohort_data['primary_country'].value_counts()\n",
    "        dist = pd.Series(0.0, index=all_countries)\n",
    "        dist.update(counts / counts.sum())\n",
    "        cohort_distributions[cohort] = dist.values\n",
    "\n",
    "jsd_results = []\n",
    "cohort_list = list(cohort_distributions.keys())\n",
    "for i in range(len(cohort_list) - 1):\n",
    "    c1, c2 = cohort_list[i], cohort_list[i + 1]\n",
    "    jsd = jensenshannon(cohort_distributions[c1], cohort_distributions[c2])\n",
    "    jsd_results.append({'Comparison': f'{c1} → {c2}', 'JSD': jsd})\n",
    "\n",
    "if len(cohort_list) >= 2:\n",
    "    jsd_first_last = jensenshannon(cohort_distributions[cohort_list[0]], cohort_distributions[cohort_list[-1]])\n",
    "    jsd_results.append({'Comparison': f'{cohort_list[0]} → {cohort_list[-1]}', 'JSD': jsd_first_last})\n",
    "\n",
    "df_jsd = pd.DataFrame(jsd_results)\n",
    "max_jsd = df_jsd['JSD'].max()\n",
    "\n",
    "# JSD interpretation\n",
    "if max_jsd < 0.05:\n",
    "    jsd_interp = \"negligible shift\"\n",
    "elif max_jsd < 0.10:\n",
    "    jsd_interp = \"minor shift\"\n",
    "elif max_jsd < 0.20:\n",
    "    jsd_interp = \"moderate shift\"\n",
    "else:\n",
    "    jsd_interp = \"substantial shift\"\n",
    "\n",
    "# Bootstrap CI for JSD\n",
    "np.random.seed(44)\n",
    "n_jsd_bootstrap = 500\n",
    "first_cohort_data = df_geo[df_geo['start_cohort'] == cohort_list[0]]['primary_country'].values\n",
    "last_cohort_data = df_geo[df_geo['start_cohort'] == cohort_list[-1]]['primary_country'].values\n",
    "\n",
    "jsd_bootstrap = []\n",
    "for _ in range(n_jsd_bootstrap):\n",
    "    boot_first = np.random.choice(first_cohort_data, size=len(first_cohort_data), replace=True)\n",
    "    boot_last = np.random.choice(last_cohort_data, size=len(last_cohort_data), replace=True)\n",
    "    all_countries_boot = np.union1d(np.unique(boot_first), np.unique(boot_last))\n",
    "    dist_first = pd.Series(boot_first).value_counts().reindex(all_countries_boot, fill_value=0) / len(boot_first)\n",
    "    dist_last = pd.Series(boot_last).value_counts().reindex(all_countries_boot, fill_value=0) / len(boot_last)\n",
    "    jsd_boot = jensenshannon(dist_first.values, dist_last.values)\n",
    "    jsd_bootstrap.append(jsd_boot)\n",
    "\n",
    "jsd_ci_low = np.percentile(jsd_bootstrap, 2.5)\n",
    "jsd_ci_high = np.percentile(jsd_bootstrap, 97.5)\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### 4.1.1 Distributional shift (Jensen-Shannon Divergence)\n",
    "\n",
    "JSD ranges 0 (identical) to ~0.83 (maximally different). Thresholds: <0.05 negligible, 0.05–0.10 minor, 0.10–0.20 moderate, >0.20 substantial.\n",
    "\n",
    "*Note: Thresholds are heuristic for ~{n_categories} countries. A permutation null would give more rigorous calibration.*\n",
    "\"\"\"))\n",
    "display(df_jsd.style.format({'JSD': '{:.3f}'}).hide(axis='index'))\n",
    "display(Markdown(f\"**{cohort_list[0]} → {cohort_list[-1]}:** JSD = {jsd_first_last:.3f} [95% CI: {jsd_ci_low:.3f}–{jsd_ci_high:.3f}] → {jsd_interp}\"))\n",
    "\n",
    "# ============================================================\n",
    "# 4.1.2 Global share by cohort\n",
    "# ============================================================\n",
    "\n",
    "top10_countries = df_country.head(10)['primary_country'].tolist()\n",
    "cohort_global_totals = df_geo.groupby('start_cohort', observed=True).size().reset_index(name='global_total')\n",
    "\n",
    "temporal_global = (\n",
    "    df_geo[df_geo['primary_country'].isin(top10_countries)]\n",
    "    .groupby(['start_cohort', 'primary_country'], observed=True)\n",
    "    .size()\n",
    "    .reset_index(name='n_trials')\n",
    ")\n",
    "temporal_global = temporal_global.merge(cohort_global_totals, on='start_cohort')\n",
    "temporal_global['global_share'] = temporal_global['n_trials'] / temporal_global['global_total'] * 100\n",
    "\n",
    "temporal_global_pivot = temporal_global.pivot_table(\n",
    "    index='primary_country', columns='start_cohort', values='global_share', fill_value=0, observed=True\n",
    ").round(1).reindex(top10_countries)\n",
    "\n",
    "display(Markdown(\"### 4.1.2 Global share by country and cohort (%)\"))\n",
    "display(temporal_global_pivot.style.format(\"{:.1f}%\"))\n",
    "\n",
    "# Top-10 combined share\n",
    "top10_combined = temporal_global.groupby('start_cohort', observed=True)['n_trials'].sum().reset_index()\n",
    "top10_combined = top10_combined.merge(cohort_global_totals, on='start_cohort')\n",
    "top10_combined['top10_share'] = top10_combined['n_trials'] / top10_combined['global_total'] * 100\n",
    "\n",
    "if len(top10_combined) >= 2:\n",
    "    delta_top10 = top10_combined.iloc[-1]['top10_share'] - top10_combined.iloc[0]['top10_share']\n",
    "    direction = \"diversifying\" if delta_top10 < -3 else \"concentrating\" if delta_top10 > 3 else \"stable\"\n",
    "    display(Markdown(f\"**Top-10 combined:** {top10_combined.iloc[0]['top10_share']:.0f}% → {top10_combined.iloc[-1]['top10_share']:.0f}% ({delta_top10:+.0f}pp, {direction})\"))\n",
    "\n",
    "# ============================================================\n",
    "# 4.1.3 Formal trend test (Spearman correlation)\n",
    "# ============================================================\n",
    "\n",
    "trend_tests = []\n",
    "for country in ['United States', 'China', 'India']:\n",
    "    if country in temporal_global_pivot.index:\n",
    "        shares = temporal_global_pivot.loc[country].values\n",
    "        cohort_idx = np.arange(len(shares))\n",
    "        if len(shares) >= 3:\n",
    "            rho, p_val = spearmanr(cohort_idx, shares)\n",
    "            trend_dir = \"increasing\" if rho > 0.3 else \"decreasing\" if rho < -0.3 else \"no clear trend\"\n",
    "            sig = \"sig.\" if p_val < 0.05 else \"n.s.\"\n",
    "            trend_tests.append({\n",
    "                'Country': country,\n",
    "                'ρ': f\"{rho:.2f}\",\n",
    "                'p': f\"{p_val:.3f}\" if p_val >= 0.001 else \"<.001\",\n",
    "                'Direction': f\"{trend_dir} ({sig})\"\n",
    "            })\n",
    "\n",
    "if trend_tests:\n",
    "    display(Markdown(\"**Trend tests (Spearman ρ of share vs cohort index):**\"))\n",
    "    display(pd.DataFrame(trend_tests).style.hide(axis='index'))\n",
    "\n",
    "# ============================================================\n",
    "# 4.1.4 Key country shifts\n",
    "# ============================================================\n",
    "\n",
    "top5_countries = df_country.head(5)['primary_country'].tolist()\n",
    "earliest_cohort, latest_cohort = '2000-2009', '2020-2025'\n",
    "\n",
    "if earliest_cohort in temporal_global_pivot.columns and latest_cohort in temporal_global_pivot.columns:\n",
    "    shifts = []\n",
    "    for country in top5_countries:\n",
    "        early = temporal_global_pivot.loc[country, earliest_cohort]\n",
    "        late = temporal_global_pivot.loc[country, latest_cohort]\n",
    "        delta = late - early\n",
    "        direction_arrow = '↑' if delta > 5 else '↓' if delta < -5 else '→'\n",
    "        shifts.append(f\"{country}: {early:.0f}% → {late:.0f}% ({delta:+.0f}pp) {direction_arrow}\")\n",
    "    \n",
    "    display(Markdown(f\"**Key shifts ({earliest_cohort} → {latest_cohort}):** \" + \" | \".join(shifts)))\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "**Confounders:**\n",
    "- FDAAA 2007 mandated US registration → early US shares inflated\n",
    "- Non-US registries growing → ClinicalTrials.gov share declining\n",
    "- Phase/condition mix varies by period\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Summary & Implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5.1 Summary (Descriptive)\n",
    "# ============================================================\n",
    "\n",
    "top_country_name = df_country.iloc[0]['primary_country']\n",
    "top_country_share = df_country.iloc[0]['market_share'] * 100\n",
    "\n",
    "n_high_lq = len(df_high_lq)\n",
    "\n",
    "# Fallback for variables that may not exist\n",
    "direction = direction if 'direction' in dir() else \"unknown\"\n",
    "trend_tests_exist = 'trend_tests' in dir() and len(trend_tests) > 0\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "## Summary\n",
    "\n",
    "**This section summarizes descriptive patterns. The methods do not support causal or inferential claims.**\n",
    "\n",
    "### Concentration (§2)\n",
    "\n",
    "Site-weighted HHI = {hhi_site_weighted:.0f}, which falls in the \"{hhi_site_interp}\" range using DOJ/FTC thresholds.\n",
    "\n",
    "- Primary-country HHI ({hhi:.0f}) is {hhi_delta_method:.0f} points higher due to multinational trial assignment.\n",
    "- Site-weighted HHI counts participation, not capacity—a country with 100 sites contributes 100× a country with 1 site, regardless of enrollment volume.\n",
    "- Neither method controls for phase or sponsor composition.\n",
    "\n",
    "### Specialization (§3)\n",
    "\n",
    "{n_high_lq:,} country–condition pairs have LQ > 1.5.\n",
    "\n",
    "**These are not validated specializations.** LQ is computed on:\n",
    "- Unnormalized condition labels (synonyms counted separately)\n",
    "- Multi-condition trials (inflating denominators for co-occurring conditions)\n",
    "- No confidence intervals (values are point estimates, not stable for small n)\n",
    "\n",
    "Sensitivity analyses (§3.2.1–3.2.3) show instability in several high-LQ pairs when restricted to single-condition trials, Phase 3, or 2015+.\n",
    "\n",
    "### Temporal (§4)\n",
    "\n",
    "JSD = {max_jsd:.3f} between earliest and latest cohorts ({jsd_interp}).\n",
    "\n",
    "- JSD thresholds are heuristic; no formal null distribution was computed.\n",
    "- Spearman trend tests have low power with only {len(cohort_list)} cohorts.\n",
    "- Confounders: FDAAA 2007 (US mandate), growth of non-US registries.\n",
    "\n",
    "### For site selection\n",
    "\n",
    "LQ indicates registration patterns, not current capacity or performance. Before using this analysis:\n",
    "\n",
    "1. Validate apparent specializations against Phase 3 and 2015+ data\n",
    "2. Recognize that condition labels are fragmented\n",
    "3. Supplement with enrollment rate and site experience data\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix A: Site Complexity by Phase/Sponsor\n",
    "\n",
    "*Supplementary analysis for feasibility planning; not directly addressing the geographic distribution question.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# A.1 Site complexity by phase\n",
    "# ============================================================\n",
    "\n",
    "df_phase_sites = df_geo[\n",
    "    (df_geo['is_interventional'] == 1) &\n",
    "    (df_geo['phase_group'].notna()) &\n",
    "    (df_geo['phase_group'] != 'Not Applicable') &\n",
    "    (df_geo['phase_group'] != 'Other')\n",
    "].copy()\n",
    "\n",
    "df_phase_sites['phase_group'] = pd.Categorical(df_phase_sites['phase_group'], categories=PHASE_ORDER_CLINICAL, ordered=True)\n",
    "\n",
    "phase_summary = (\n",
    "    df_phase_sites\n",
    "    .groupby('phase_group', observed=True)\n",
    "    .agg(\n",
    "        n_trials=('study_id', 'nunique'),\n",
    "        median_sites=('n_sites', 'median'),\n",
    "        mean_sites=('n_sites', 'mean'),\n",
    "        q75_sites=('n_sites', lambda x: x.quantile(0.75)),\n",
    "        pct_multinational=('is_multinational', 'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "phase_summary['pct_multinational'] = phase_summary['pct_multinational'] * 100\n",
    "\n",
    "display(Markdown(\"### A.1 Site complexity by phase (interventional)\"))\n",
    "display(\n",
    "    phase_summary\n",
    "    .rename(columns={\n",
    "        'phase_group': 'Phase', 'n_trials': 'N', 'median_sites': 'Median',\n",
    "        'mean_sites': 'Mean', 'q75_sites': 'Q75', 'pct_multinational': 'Multinational %',\n",
    "    })\n",
    "    .style.format({'N': '{:,.0f}', 'Median': '{:.0f}', 'Mean': '{:.1f}', 'Q75': '{:.0f}', 'Multinational %': '{:.1f}%'})\n",
    "    .hide(axis='index')\n",
    ")\n",
    "\n",
    "# Key values for reference\n",
    "p1_sites = phase_summary.loc[phase_summary['phase_group'] == 'Phase 1', 'median_sites'].values\n",
    "p3_sites = phase_summary.loc[phase_summary['phase_group'] == 'Phase 3', 'median_sites'].values\n",
    "p1_val = int(p1_sites[0]) if len(p1_sites) > 0 else 'N/A'\n",
    "p3_val = int(p3_sites[0]) if len(p3_sites) > 0 else 'N/A'\n",
    "site_ratio = p3_val / p1_val if isinstance(p1_val, int) and p1_val > 0 else 'N/A'\n",
    "\n",
    "display(Markdown(f\"Phase 3 median = {p3_val} sites vs Phase 1 = {p1_val} ({site_ratio:.0f}× ratio)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# A.2 Sponsor effect on site count (Phase 3)\n",
    "# ============================================================\n",
    "\n",
    "p3_data = df_phase_sites[df_phase_sites['phase_group'] == 'Phase 3'].copy()\n",
    "p3_industry = p3_data[p3_data['is_industry_sponsor'] == 1]['n_sites']\n",
    "p3_non_industry = p3_data[p3_data['is_industry_sponsor'] == 0]['n_sites']\n",
    "\n",
    "u_stat, p_mw = mannwhitneyu(p3_industry, p3_non_industry, alternative='two-sided')\n",
    "n1, n2 = len(p3_industry), len(p3_non_industry)\n",
    "r_biserial = 1 - (2 * u_stat) / (n1 * n2)\n",
    "effect_label = interpret_effect_size(r_biserial, metric=\"r\")\n",
    "median_ratio = p3_industry.median() / p3_non_industry.median() if p3_non_industry.median() > 0 else float('inf')\n",
    "\n",
    "display(Markdown(f\"\"\"\n",
    "### A.2 Sponsor effect (Phase 3) — Descriptive Only\n",
    "\n",
    "| Sponsor | N | Median Sites |\n",
    "|---------|---|--------------|\n",
    "| Industry | {n1:,} | {p3_industry.median():.0f} |\n",
    "| Non-industry | {n2:,} | {p3_non_industry.median():.0f} |\n",
    "\n",
    "Mann-Whitney r = {r_biserial:.2f} ({effect_label}), p < 0.001. Industry Phase 3 trials have {median_ratio:.1f}× higher median site count.\n",
    "\"\"\"))\n",
    "\n",
    "# ============================================================\n",
    "# Stratified analysis: control for therapeutic area (oncology vs non-oncology)\n",
    "# ============================================================\n",
    "\n",
    "# Identify oncology trials (heuristic: condition contains \"cancer\", \"tumor\", \"carcinoma\", etc.)\n",
    "oncology_keywords = ['cancer', 'tumor', 'tumour', 'carcinoma', 'leukemia', 'lymphoma', 'melanoma', 'sarcoma', 'oncolog']\n",
    "\n",
    "# Merge with conditions to identify oncology trials\n",
    "df_conds = pd.read_sql(\"\"\"\n",
    "    SELECT c.study_id, LOWER(c.condition_name) AS condition_lower\n",
    "    FROM conditions c\n",
    "    JOIN v_studies_clean s ON c.study_id = s.study_id\n",
    "    WHERE s.is_start_year_in_scope = 1\n",
    "\"\"\", conn)\n",
    "\n",
    "oncology_studies = df_conds[df_conds['condition_lower'].str.contains('|'.join(oncology_keywords), na=False)]['study_id'].unique()\n",
    "p3_data['is_oncology'] = p3_data['study_id'].isin(oncology_studies).astype(int)\n",
    "\n",
    "# Stratified comparison\n",
    "strat_results = []\n",
    "for is_onc, label in [(1, 'Oncology'), (0, 'Non-oncology')]:\n",
    "    stratum = p3_data[p3_data['is_oncology'] == is_onc]\n",
    "    ind = stratum[stratum['is_industry_sponsor'] == 1]['n_sites']\n",
    "    non_ind = stratum[stratum['is_industry_sponsor'] == 0]['n_sites']\n",
    "    \n",
    "    if len(ind) >= 10 and len(non_ind) >= 10:\n",
    "        u, p = mannwhitneyu(ind, non_ind, alternative='two-sided')\n",
    "        r = 1 - (2 * u) / (len(ind) * len(non_ind))\n",
    "        ratio = ind.median() / non_ind.median() if non_ind.median() > 0 else float('inf')\n",
    "        \n",
    "        strat_results.append({\n",
    "            'Stratum': label,\n",
    "            'Industry (n, median)': f\"{len(ind):,}, {ind.median():.0f}\",\n",
    "            'Non-industry (n, median)': f\"{len(non_ind):,}, {non_ind.median():.0f}\",\n",
    "            'Ratio': f\"{ratio:.1f}×\",\n",
    "            'r': f\"{r:.2f}\",\n",
    "        })\n",
    "    else:\n",
    "        strat_results.append({\n",
    "            'Stratum': label,\n",
    "            'Industry (n, median)': f\"{len(ind):,}, —\" if len(ind) < 10 else f\"{len(ind):,}, {ind.median():.0f}\",\n",
    "            'Non-industry (n, median)': f\"{len(non_ind):,}, —\" if len(non_ind) < 10 else f\"{len(non_ind):,}, {non_ind.median():.0f}\",\n",
    "            'Ratio': 'n/a',\n",
    "            'r': 'n/a',\n",
    "        })\n",
    "\n",
    "df_strat = pd.DataFrame(strat_results)\n",
    "display(Markdown(\"**Stratified by therapeutic area:**\"))\n",
    "display(df_strat.style.hide(axis='index'))\n",
    "\n",
    "# Check if sponsor effect attenuates within strata\n",
    "onc_r = float(strat_results[0]['r']) if strat_results[0]['r'] != 'n/a' else None\n",
    "non_onc_r = float(strat_results[1]['r']) if strat_results[1]['r'] != 'n/a' else None\n",
    "overall_r = r_biserial\n",
    "\n",
    "if onc_r is not None and non_onc_r is not None:\n",
    "    avg_strat_r = (abs(onc_r) + abs(non_onc_r)) / 2\n",
    "    confounding_note = \"attenuates\" if avg_strat_r < abs(overall_r) * 0.8 else \"persists\"\n",
    "    display(Markdown(f\"\"\"\n",
    "*Effect {confounding_note} after stratification (overall r = {overall_r:.2f}, oncology r = {onc_r:.2f}, non-oncology r = {non_onc_r:.2f}). This suggests {'therapeutic area confounding' if confounding_note == 'attenuates' else 'sponsor effect is robust to therapeutic area'}.*\n",
    "\"\"\"))\n",
    "else:\n",
    "    display(Markdown(\"*Insufficient data for stratified comparison.*\"))\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "**Interpretation:** This appendix provides descriptive context for feasibility planning. The sponsor–site relationship reflects multiple factors (indication, enrollment targets, regulatory requirements) that are not disentangled here.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
